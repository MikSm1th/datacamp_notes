{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set_style('darkgrid')\n",
    "mpl.rcParams['figure.figsize'] = [24,16]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Review of pipelines using sklearn\n",
    "- Takes a list of named 2-tuples (name, pipeline_step) as input \n",
    "- Tuples can contain any arbitrary scikit-learn compatible estimator or transformer object\n",
    "- Pipeline implements fit/predict methods\n",
    "- Can be used as input estimator into grid/randomized search and cross_val_score methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(506, 13) (506,)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import load_boston\n",
    "data = load_boston()\n",
    "X, y = data.data, data.target\n",
    "print(X.shape, y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import cross_val_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_pipeline = Pipeline([('st_scaler', StandardScaler()),\n",
    "                        ('rf_model', RandomForestRegressor())])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = cross_val_score(rf_pipeline, X,y,\n",
    "                        scoring='neg_mean_squared_error', cv=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final RMSE: 4.186628738586899\n"
     ]
    }
   ],
   "source": [
    "final_avg_rmse = np.mean(np.sqrt(np.abs(scores)))\n",
    "print(\"Final RMSE:\", final_avg_rmse)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocessing I: LabelEncoder and OneHotEncoder\n",
    "- `LabelEncoder`: Converts a categorical column of strings into integers\n",
    "- `OneHotEncoder`: Takes the column of integers and encodes them as dummy variables\n",
    "- Cannot be done within a pipeline.\n",
    "\n",
    "### Preprocessing II: DictVectorizer\n",
    "- Traditionally used in text processing\n",
    "- Converts lists of feature mappings into vectors\n",
    "- Need to convert DataFrame into a list of dictionary entriesdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1460, 21)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('data/ames_unprocessed_data.csv')\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  MSZoning Neighborhood BldgType HouseStyle PavedDrive\n",
      "0       RL      CollgCr     1Fam     2Story          Y\n",
      "1       RL      Veenker     1Fam     1Story          Y\n",
      "2       RL      CollgCr     1Fam     2Story          Y\n",
      "3       RL      Crawfor     1Fam     2Story          Y\n",
      "4       RL      NoRidge     1Fam     2Story          Y\n",
      "   MSZoning  Neighborhood  BldgType  HouseStyle  PavedDrive\n",
      "0         3             5         0           5           2\n",
      "1         3            24         0           2           2\n",
      "2         3             5         0           5           2\n",
      "3         3             6         0           5           2\n",
      "4         3            15         0           5           2\n"
     ]
    }
   ],
   "source": [
    "# Import LabelEncoder\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# Fill missing values with 0\n",
    "df.LotFrontage = df.LotFrontage.fillna(0)\n",
    "\n",
    "# Create a boolean mask for categorical columns\n",
    "categorical_mask = (df.dtypes == object)\n",
    "\n",
    "# Get list of categorical column names\n",
    "categorical_columns = df.columns[categorical_mask].tolist()\n",
    "\n",
    "# Print the head of the categorical columns\n",
    "print(df[categorical_columns].head())\n",
    "\n",
    "# Create LabelEncoder object: le\n",
    "le = LabelEncoder()\n",
    "\n",
    "# Apply LabelEncoder to categorical columns\n",
    "df[categorical_columns] = df[categorical_columns].apply(lambda x: le.fit_transform(x))\n",
    "\n",
    "# Print the head of the LabelEncoded categorical columns\n",
    "print(df[categorical_columns].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MSZoning</th>\n",
       "      <th>Neighborhood</th>\n",
       "      <th>BldgType</th>\n",
       "      <th>HouseStyle</th>\n",
       "      <th>PavedDrive</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>24</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3</td>\n",
       "      <td>15</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   MSZoning  Neighborhood  BldgType  HouseStyle  PavedDrive\n",
       "0         3             5         0           5           2\n",
       "1         3            24         0           2           2\n",
       "2         3             5         0           5           2\n",
       "3         3             6         0           5           2\n",
       "4         3            15         0           5           2"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_processed = df.drop(categorical_columns, axis=1)\n",
    "df_processed = df_processed.to_numpy()\n",
    "#df_processed.head(3)\n",
    "df_ohe = df[categorical_columns]\n",
    "df_ohe.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[6.000e+01 6.500e+01 8.450e+03 7.000e+00 5.000e+00 2.003e+03 0.000e+00\n",
      "  1.710e+03 1.000e+00 0.000e+00 2.000e+00 1.000e+00 3.000e+00 0.000e+00\n",
      "  5.480e+02 2.085e+05 0.000e+00 0.000e+00 0.000e+00 1.000e+00 0.000e+00\n",
      "  0.000e+00 0.000e+00 0.000e+00 0.000e+00 0.000e+00 1.000e+00 0.000e+00\n",
      "  0.000e+00 0.000e+00 0.000e+00 0.000e+00 0.000e+00 0.000e+00 0.000e+00\n",
      "  0.000e+00 0.000e+00 0.000e+00 0.000e+00 0.000e+00 0.000e+00 0.000e+00\n",
      "  0.000e+00 0.000e+00 0.000e+00 0.000e+00 1.000e+00 0.000e+00 0.000e+00\n",
      "  0.000e+00 0.000e+00 0.000e+00 0.000e+00 0.000e+00 0.000e+00 0.000e+00\n",
      "  1.000e+00 0.000e+00 0.000e+00 0.000e+00 0.000e+00 1.000e+00]\n",
      " [2.000e+01 8.000e+01 9.600e+03 6.000e+00 8.000e+00 1.976e+03 0.000e+00\n",
      "  1.262e+03 0.000e+00 1.000e+00 2.000e+00 0.000e+00 3.000e+00 1.000e+00\n",
      "  4.600e+02 1.815e+05 0.000e+00 0.000e+00 0.000e+00 1.000e+00 0.000e+00\n",
      "  0.000e+00 0.000e+00 0.000e+00 0.000e+00 0.000e+00 0.000e+00 0.000e+00\n",
      "  0.000e+00 0.000e+00 0.000e+00 0.000e+00 0.000e+00 0.000e+00 0.000e+00\n",
      "  0.000e+00 0.000e+00 0.000e+00 0.000e+00 0.000e+00 0.000e+00 0.000e+00\n",
      "  0.000e+00 0.000e+00 0.000e+00 1.000e+00 1.000e+00 0.000e+00 0.000e+00\n",
      "  0.000e+00 0.000e+00 0.000e+00 0.000e+00 1.000e+00 0.000e+00 0.000e+00\n",
      "  0.000e+00 0.000e+00 0.000e+00 0.000e+00 0.000e+00 1.000e+00]\n",
      " [6.000e+01 6.800e+01 1.125e+04 7.000e+00 5.000e+00 2.001e+03 1.000e+00\n",
      "  1.786e+03 1.000e+00 0.000e+00 2.000e+00 1.000e+00 3.000e+00 1.000e+00\n",
      "  6.080e+02 2.235e+05 0.000e+00 0.000e+00 0.000e+00 1.000e+00 0.000e+00\n",
      "  0.000e+00 0.000e+00 0.000e+00 0.000e+00 0.000e+00 1.000e+00 0.000e+00\n",
      "  0.000e+00 0.000e+00 0.000e+00 0.000e+00 0.000e+00 0.000e+00 0.000e+00\n",
      "  0.000e+00 0.000e+00 0.000e+00 0.000e+00 0.000e+00 0.000e+00 0.000e+00\n",
      "  0.000e+00 0.000e+00 0.000e+00 0.000e+00 1.000e+00 0.000e+00 0.000e+00\n",
      "  0.000e+00 0.000e+00 0.000e+00 0.000e+00 0.000e+00 0.000e+00 0.000e+00\n",
      "  1.000e+00 0.000e+00 0.000e+00 0.000e+00 0.000e+00 1.000e+00]\n",
      " [7.000e+01 6.000e+01 9.550e+03 7.000e+00 5.000e+00 1.915e+03 1.000e+00\n",
      "  1.717e+03 1.000e+00 0.000e+00 1.000e+00 0.000e+00 3.000e+00 1.000e+00\n",
      "  6.420e+02 1.400e+05 0.000e+00 0.000e+00 0.000e+00 1.000e+00 0.000e+00\n",
      "  0.000e+00 0.000e+00 0.000e+00 0.000e+00 0.000e+00 0.000e+00 1.000e+00\n",
      "  0.000e+00 0.000e+00 0.000e+00 0.000e+00 0.000e+00 0.000e+00 0.000e+00\n",
      "  0.000e+00 0.000e+00 0.000e+00 0.000e+00 0.000e+00 0.000e+00 0.000e+00\n",
      "  0.000e+00 0.000e+00 0.000e+00 0.000e+00 1.000e+00 0.000e+00 0.000e+00\n",
      "  0.000e+00 0.000e+00 0.000e+00 0.000e+00 0.000e+00 0.000e+00 0.000e+00\n",
      "  1.000e+00 0.000e+00 0.000e+00 0.000e+00 0.000e+00 1.000e+00]\n",
      " [6.000e+01 8.400e+01 1.426e+04 8.000e+00 5.000e+00 2.000e+03 0.000e+00\n",
      "  2.198e+03 1.000e+00 0.000e+00 2.000e+00 1.000e+00 4.000e+00 1.000e+00\n",
      "  8.360e+02 2.500e+05 0.000e+00 0.000e+00 0.000e+00 1.000e+00 0.000e+00\n",
      "  0.000e+00 0.000e+00 0.000e+00 0.000e+00 0.000e+00 0.000e+00 0.000e+00\n",
      "  0.000e+00 0.000e+00 0.000e+00 0.000e+00 0.000e+00 0.000e+00 0.000e+00\n",
      "  0.000e+00 1.000e+00 0.000e+00 0.000e+00 0.000e+00 0.000e+00 0.000e+00\n",
      "  0.000e+00 0.000e+00 0.000e+00 0.000e+00 1.000e+00 0.000e+00 0.000e+00\n",
      "  0.000e+00 0.000e+00 0.000e+00 0.000e+00 0.000e+00 0.000e+00 0.000e+00\n",
      "  1.000e+00 0.000e+00 0.000e+00 0.000e+00 0.000e+00 1.000e+00]]\n",
      "(1460, 21)\n",
      "(1460, 62)\n"
     ]
    }
   ],
   "source": [
    "# Import OneHotEncoder\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "# Create OneHotEncoder: ohe\n",
    "ohe = OneHotEncoder(sparse=False)\n",
    "\n",
    "# Apply OneHotEncoder to categorical columns - output is no longer a dataframe: df_encoded\n",
    "df_encoded_temp = ohe.fit_transform(df_ohe)\n",
    "\n",
    "df_encoded = np.concatenate((df_processed, df_encoded_temp), axis=1)\n",
    "\n",
    "# Print first 5 rows of the resulting dataset - again, this will no longer be a pandas dataframe\n",
    "print(df_encoded[:5, :])\n",
    "\n",
    "# Print the shape of the original DataFrame\n",
    "print(df.shape)\n",
    "\n",
    "# Print the shape of the transformed array\n",
    "print(df_encoded.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[0;31mSignature:\u001b[0m\n",
       " \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mlabels\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mindex\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mcolumns\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mlevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0minplace\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0merrors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'raise'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
       "\u001b[0;31mDocstring:\u001b[0m\n",
       "Drop specified labels from rows or columns.\n",
       "\n",
       "Remove rows or columns by specifying label names and corresponding\n",
       "axis, or by specifying directly index or column names. When using a\n",
       "multi-index, labels on different levels can be removed by specifying\n",
       "the level.\n",
       "\n",
       "Parameters\n",
       "----------\n",
       "labels : single label or list-like\n",
       "    Index or column labels to drop.\n",
       "axis : {0 or 'index', 1 or 'columns'}, default 0\n",
       "    Whether to drop labels from the index (0 or 'index') or\n",
       "    columns (1 or 'columns').\n",
       "index : single label or list-like\n",
       "    Alternative to specifying axis (``labels, axis=0``\n",
       "    is equivalent to ``index=labels``).\n",
       "\n",
       "    .. versionadded:: 0.21.0\n",
       "columns : single label or list-like\n",
       "    Alternative to specifying axis (``labels, axis=1``\n",
       "    is equivalent to ``columns=labels``).\n",
       "\n",
       "    .. versionadded:: 0.21.0\n",
       "level : int or level name, optional\n",
       "    For MultiIndex, level from which the labels will be removed.\n",
       "inplace : bool, default False\n",
       "    If True, do operation inplace and return None.\n",
       "errors : {'ignore', 'raise'}, default 'raise'\n",
       "    If 'ignore', suppress error and only existing labels are\n",
       "    dropped.\n",
       "\n",
       "Returns\n",
       "-------\n",
       "DataFrame\n",
       "    DataFrame without the removed index or column labels.\n",
       "\n",
       "Raises\n",
       "------\n",
       "KeyError\n",
       "    If any of the labels is not found in the selected axis.\n",
       "\n",
       "See Also\n",
       "--------\n",
       "DataFrame.loc : Label-location based indexer for selection by label.\n",
       "DataFrame.dropna : Return DataFrame with labels on given axis omitted\n",
       "    where (all or any) data are missing.\n",
       "DataFrame.drop_duplicates : Return DataFrame with duplicate rows\n",
       "    removed, optionally only considering certain columns.\n",
       "Series.drop : Return Series with specified index labels removed.\n",
       "\n",
       "Examples\n",
       "--------\n",
       ">>> df = pd.DataFrame(np.arange(12).reshape(3, 4),\n",
       "...                   columns=['A', 'B', 'C', 'D'])\n",
       ">>> df\n",
       "   A  B   C   D\n",
       "0  0  1   2   3\n",
       "1  4  5   6   7\n",
       "2  8  9  10  11\n",
       "\n",
       "Drop columns\n",
       "\n",
       ">>> df.drop(['B', 'C'], axis=1)\n",
       "   A   D\n",
       "0  0   3\n",
       "1  4   7\n",
       "2  8  11\n",
       "\n",
       ">>> df.drop(columns=['B', 'C'])\n",
       "   A   D\n",
       "0  0   3\n",
       "1  4   7\n",
       "2  8  11\n",
       "\n",
       "Drop a row by index\n",
       "\n",
       ">>> df.drop([0, 1])\n",
       "   A  B   C   D\n",
       "2  8  9  10  11\n",
       "\n",
       "Drop columns and/or rows of MultiIndex DataFrame\n",
       "\n",
       ">>> midx = pd.MultiIndex(levels=[['lama', 'cow', 'falcon'],\n",
       "...                              ['speed', 'weight', 'length']],\n",
       "...                      codes=[[0, 0, 0, 1, 1, 1, 2, 2, 2],\n",
       "...                             [0, 1, 2, 0, 1, 2, 0, 1, 2]])\n",
       ">>> df = pd.DataFrame(index=midx, columns=['big', 'small'],\n",
       "...                   data=[[45, 30], [200, 100], [1.5, 1], [30, 20],\n",
       "...                         [250, 150], [1.5, 0.8], [320, 250],\n",
       "...                         [1, 0.8], [0.3, 0.2]])\n",
       ">>> df\n",
       "                big     small\n",
       "lama    speed   45.0    30.0\n",
       "        weight  200.0   100.0\n",
       "        length  1.5     1.0\n",
       "cow     speed   30.0    20.0\n",
       "        weight  250.0   150.0\n",
       "        length  1.5     0.8\n",
       "falcon  speed   320.0   250.0\n",
       "        weight  1.0     0.8\n",
       "        length  0.3     0.2\n",
       "\n",
       ">>> df.drop(index='cow', columns='small')\n",
       "                big\n",
       "lama    speed   45.0\n",
       "        weight  200.0\n",
       "        length  1.5\n",
       "falcon  speed   320.0\n",
       "        weight  1.0\n",
       "        length  0.3\n",
       "\n",
       ">>> df.drop(index='length', level=1)\n",
       "                big     small\n",
       "lama    speed   45.0    30.0\n",
       "        weight  200.0   100.0\n",
       "cow     speed   30.0    20.0\n",
       "        weight  250.0   150.0\n",
       "falcon  speed   320.0   250.0\n",
       "        weight  1.0     0.8\n",
       "\u001b[0;31mFile:\u001b[0m      ~/anaconda3/lib/python3.6/site-packages/pandas/core/frame.py\n",
       "\u001b[0;31mType:\u001b[0m      function\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "? pd.DataFrame.drop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
