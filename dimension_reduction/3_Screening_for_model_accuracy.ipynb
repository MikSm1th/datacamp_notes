{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set_style('darkgrid')\n",
    "mpl.rcParams['figure.figsize'] = [18,10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "non_numeric = ['BMI_class', 'Height_class', 'Gender', 'Component', 'Branch']\n",
    "\n",
    "def load_ansur(cols_to_drop):\n",
    "    df_m = pd.read_csv('data/ANSUR_II_MALE.csv')\n",
    "    df_f = pd.read_csv('data/ANSUR_II_FEMALE.csv')\n",
    "    ansur_df = pd.concat([df_m, df_f], axis=0)\n",
    "\n",
    "    X = ansur_df.drop(non_numeric, axis=1)\n",
    "    y = ansur_df['Gender']\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3)\n",
    "    return X, y, X_train, X_test, y_train, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y, X_train, X_test, y_train, y_test = load_ansur(non_numeric)\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train_std = scaler.fit_transform(X_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating a logistic regression model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "lr = LogisticRegression()\n",
    "lr.fit(X_train_std, y_train)\n",
    "\n",
    "X_test_std = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n"
     ]
    }
   ],
   "source": [
    "y_pred = lr.predict(X_test_std)\n",
    "print(accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inspecting the feature coefficients "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.16538097  0.11415374 -0.11988966 -0.35318174 -0.10102145 -0.12958967\n",
      "  0.29849897  0.62395995  0.78708997 -0.71298706]\n"
     ]
    }
   ],
   "source": [
    "print(lr.coef_[0][:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'abdominalextensiondepthsitting': 0.16538096650652276,\n",
       " 'acromialheight': 0.114153743902519,\n",
       " 'acromionradialelength': 0.11988966102355153,\n",
       " 'anklecircumference': 0.35318174207131736,\n",
       " 'axillaheight': 0.10102145271792597,\n",
       " 'balloffootcircumference': 0.12958967443975758,\n",
       " 'balloffootlength': 0.29849897180764645,\n",
       " 'biacromialbreadth': 0.6239599493764185,\n",
       " 'bicepscircumferenceflexed': 0.7870899693843955,\n",
       " 'bicristalbreadth': 0.7129870615083279}"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "coef_dict = dict(zip(X.columns, abs(lr.coef_[0])))\n",
    "\n",
    "{k: v for i, (k, v) in enumerate(coef_dict.items()) if i < 10}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "low_coef = {k: v for k, v in coef_dict.items() if v < .401}\n",
    "\n",
    "cols = [k for k, v in low_coef.items()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n"
     ]
    }
   ],
   "source": [
    "X.drop(cols, axis=1, inplace=True)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3)\n",
    "\n",
    "lr.fit(scaler.fit_transform(X_train), y_train)\n",
    "\n",
    "print(accuracy_score(y_test, lr.predict(scaler.transform(X_test))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y, X_train, X_test, y_train, y_test = load_ansur(non_numeric)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train_std = scaler.fit_transform(X_train)\n",
    "X_test_std = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RFE(estimator=LogisticRegression(C=1.0, class_weight=None, dual=False,\n",
       "                                 fit_intercept=True, intercept_scaling=1,\n",
       "                                 l1_ratio=None, max_iter=100,\n",
       "                                 multi_class='auto', n_jobs=None, penalty='l2',\n",
       "                                 random_state=None, solver='lbfgs', tol=0.0001,\n",
       "                                 verbose=0, warm_start=False),\n",
       "    n_features_to_select=5, step=1, verbose=0)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_selection import RFE\n",
    "\n",
    "rfe = RFE(estimator=LogisticRegression(), n_features_to_select=5, verbose=0)\n",
    "rfe.fit(X_train_std, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['chestdepth', 'hipbreadthsitting', 'lateralmalleolusheight',\n",
       "       'neckcircumference', 'shouldercircumference'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.columns[rfe.support_]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(dict(zip(X.columns, rfe.ranking_)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9950576606260296\n"
     ]
    }
   ],
   "source": [
    "print(accuracy_score(y_test, rfe.predict(X_test_std)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_pima(cols_to_drop):\n",
    "    df = pd.read_csv('data/PimaIndians.csv')\n",
    "\n",
    "    X = df.drop(cols_to_drop, axis=1)\n",
    "    y = df['test']\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3)\n",
    "    return X, y, X_train, X_test, y_train, y_test\n",
    "\n",
    "X, y, X_train, X_test, y_train, y_test = load_pima('test')\n",
    "\n",
    "scaler = StandardScaler()\n",
    "lr = LogisticRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "78.8% accuracy on test set.\n",
      "{'pregnant': 0.17, 'glucose': 1.24, 'diastolic': 0.05, 'triceps': 0.05, 'insulin': 0.03, 'bmi': 0.6, 'family': 0.64, 'age': 0.42}\n"
     ]
    }
   ],
   "source": [
    "# Fit the scaler on the training features and transform these in one go\n",
    "X_train_std = scaler.fit_transform(X_train)\n",
    "\n",
    "# Fit the logistic regression model on the scaled training data\n",
    "lr.fit(X_train_std, y_train)\n",
    "\n",
    "# Scale the test features\n",
    "X_test_std = scaler.transform(X_test)\n",
    "\n",
    "# Predict diabetes presence on the scaled test set\n",
    "y_pred = lr.predict(X_test_std)\n",
    "\n",
    "# Prints accuracy metrics and feature coefficients\n",
    "print(\"{0:.1%} accuracy on test set.\".format(accuracy_score(y_test, y_pred))) \n",
    "print(dict(zip(X.columns, abs(lr.coef_[0]).round(2))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting estimator with 8 features.\n",
      "Fitting estimator with 7 features.\n",
      "Fitting estimator with 6 features.\n",
      "Fitting estimator with 5 features.\n",
      "Fitting estimator with 4 features.\n",
      "{'pregnant': 2, 'glucose': 1, 'diastolic': 5, 'triceps': 4, 'insulin': 6, 'bmi': 1, 'family': 3, 'age': 1}\n",
      "Index(['glucose', 'bmi', 'age'], dtype='object')\n",
      "81.4% accuracy on test set.\n"
     ]
    }
   ],
   "source": [
    "X, y, X_train, X_test, y_train, y_test = load_pima('test')\n",
    "\n",
    "X_train_std = scaler.fit_transform(X_train)\n",
    "X_test_std = scaler.transform(X_test)\n",
    "\n",
    "# Create the RFE with a LogisticRegression estimator and 3 features to select\n",
    "rfe = RFE(estimator=LogisticRegression(), n_features_to_select=3, verbose=1)\n",
    "\n",
    "# Fits the eliminator to the data\n",
    "rfe.fit(X_train_std, y_train)\n",
    "\n",
    "# Print the features and their ranking (high = dropped early on)\n",
    "print(dict(zip(X.columns, rfe.ranking_)))\n",
    "\n",
    "# Print the features that are not eliminated\n",
    "print(X.columns[rfe.support_])\n",
    "\n",
    "# Calculates the test set accuracy\n",
    "acc = accuracy_score(y_test, rfe.predict(X_test_std))\n",
    "print(\"{0:.1%} accuracy on test set.\".format(acc)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y, X_train, X_test, y_train, y_test = load_ansur(non_numeric)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,\n",
       "                       criterion='gini', max_depth=None, max_features='auto',\n",
       "                       max_leaf_nodes=None, max_samples=None,\n",
       "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                       min_samples_leaf=1, min_samples_split=2,\n",
       "                       min_weight_fraction_leaf=0.0, n_estimators=100,\n",
       "                       n_jobs=None, oob_score=False, random_state=None,\n",
       "                       verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "rf = RandomForestClassifier()\n",
    "\n",
    "rf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9928610653487095\n"
     ]
    }
   ],
   "source": [
    "print(accuracy_score(y_test, rf.predict(X_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.00206631 0.00085132 0.00037488 0.00099212 0.0009641  0.01011892\n",
      " 0.00136837 0.07127259 0.00220716 0.00504109 0.02323911 0.02559065\n",
      " 0.00066058 0.00582394 0.00151748 0.01573475 0.00315212 0.0008796\n",
      " 0.00213329 0.00108655 0.00277378 0.00654128 0.00074444 0.00149168\n",
      " 0.00697598 0.01908575 0.00060196 0.00652669 0.00057112 0.0010713\n",
      " 0.00090475 0.00235291 0.00032742 0.01524344 0.00487481 0.01896129\n",
      " 0.00138604 0.03525249 0.00536859 0.00139054 0.00063838 0.05699923\n",
      " 0.06933629 0.0008951  0.00104036 0.00117986 0.00036979 0.02360453\n",
      " 0.00034314 0.01425212 0.02788376 0.00105118 0.00033213 0.00283422\n",
      " 0.00643822 0.00041519 0.00078931 0.00135627 0.01906717 0.00481514\n",
      " 0.00248674 0.16255435 0.08284147 0.00557559 0.00035937 0.00639895\n",
      " 0.00174778 0.05067019 0.00737041 0.00115761 0.00544367 0.02082252\n",
      " 0.00149705 0.00085596 0.00481622 0.00134939 0.00671688 0.00141185\n",
      " 0.00063185 0.0006193  0.00055278 0.00098847 0.00083951 0.00882373\n",
      " 0.00096772 0.00210244 0.00125869 0.00062147 0.00042504 0.06570952\n",
      " 0.00037402 0.00219411 0.00756418 0.00108855]\n"
     ]
    }
   ],
   "source": [
    "print(rf.feature_importances_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[False False False False False False False  True False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False  True False False False  True  True False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False  True  True False False False False  True False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False  True False False False False]\n"
     ]
    }
   ],
   "source": [
    "mask = rf.feature_importances_ > 0.03\n",
    "print(mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['biacromialbreadth', 'forearmcircumferenceflexed', 'handbreadth',\n",
      "       'handcircumference', 'neckcircumference', 'neckcircumferencebase',\n",
      "       'shouldercircumference', 'wristcircumference'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "X_reduced = X_train.loc[:, mask]\n",
    "print(X_reduced.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RFE with random forests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting estimator with 94 features.\n",
      "Fitting estimator with 84 features.\n",
      "Fitting estimator with 74 features.\n",
      "Fitting estimator with 64 features.\n",
      "Fitting estimator with 54 features.\n",
      "Fitting estimator with 44 features.\n",
      "Fitting estimator with 34 features.\n",
      "Fitting estimator with 24 features.\n",
      "Fitting estimator with 14 features.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RFE(estimator=RandomForestClassifier(bootstrap=True, ccp_alpha=0.0,\n",
       "                                     class_weight=None, criterion='gini',\n",
       "                                     max_depth=None, max_features='auto',\n",
       "                                     max_leaf_nodes=None, max_samples=None,\n",
       "                                     min_impurity_decrease=0.0,\n",
       "                                     min_impurity_split=None,\n",
       "                                     min_samples_leaf=1, min_samples_split=2,\n",
       "                                     min_weight_fraction_leaf=0.0,\n",
       "                                     n_estimators=100, n_jobs=None,\n",
       "                                     oob_score=False, random_state=None,\n",
       "                                     verbose=0, warm_start=False),\n",
       "    n_features_to_select=6, step=10, verbose=1)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_selection import RFE\n",
    "\n",
    "rfe = RFE(estimator=RandomForestClassifier(), \n",
    "          n_features_to_select=6, step=10, \n",
    "            verbose=1)\n",
    "\n",
    "rfe.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['biacromialbreadth', 'handbreadth', 'handcircumference',\n",
      "       'neckcircumference', 'neckcircumferencebase', 'shouldercircumference'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print(X_train.columns[rfe.support_])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y, X_train, X_test, y_train, y_test = load_pima('test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'pregnant': 0.07, 'glucose': 0.23, 'diastolic': 0.08, 'triceps': 0.07, 'insulin': 0.16, 'bmi': 0.12, 'family': 0.12, 'age': 0.16}\n",
      "72.9% accuracy on test set.\n"
     ]
    }
   ],
   "source": [
    "# Fit the random forest model to the training data\n",
    "rf = RandomForestClassifier(random_state=0)\n",
    "rf.fit(X_train, y_train)\n",
    "\n",
    "# Calculate the accuracy\n",
    "acc = accuracy_score(y_test, rf.predict(X_test))\n",
    "\n",
    "# Print the importances per feature\n",
    "print(dict(zip(X_train.columns, rf.feature_importances_.round(2))))\n",
    "\n",
    "# Print accuracy\n",
    "print(\"{0:.1%} accuracy on test set.\".format(acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[False  True False False  True False False  True]\n"
     ]
    }
   ],
   "source": [
    "# Create a mask for features importances above the threshold\n",
    "mask = rf.feature_importances_ > 0.15\n",
    "\n",
    "# Prints out the mask\n",
    "print(mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['glucose', 'insulin', 'age'], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "# Create a mask for features importances above the threshold\n",
    "mask = rf.feature_importances_ > 0.15\n",
    "\n",
    "# Apply the mask to the feature dataset X\n",
    "reduced_X = X_train.loc[:, mask]\n",
    "\n",
    "# prints out the selected column names\n",
    "print(reduced_X.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Wrap the feature eliminator around the random forest model\n",
    "rfe = RFE(estimator=RandomForestClassifier(), n_features_to_select=2, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting estimator with 8 features.\n",
      "Fitting estimator with 7 features.\n",
      "Fitting estimator with 6 features.\n",
      "Fitting estimator with 5 features.\n",
      "Fitting estimator with 4 features.\n",
      "Fitting estimator with 3 features.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RFE(estimator=RandomForestClassifier(bootstrap=True, ccp_alpha=0.0,\n",
       "                                     class_weight=None, criterion='gini',\n",
       "                                     max_depth=None, max_features='auto',\n",
       "                                     max_leaf_nodes=None, max_samples=None,\n",
       "                                     min_impurity_decrease=0.0,\n",
       "                                     min_impurity_split=None,\n",
       "                                     min_samples_leaf=1, min_samples_split=2,\n",
       "                                     min_weight_fraction_leaf=0.0,\n",
       "                                     n_estimators=100, n_jobs=None,\n",
       "                                     oob_score=False, random_state=None,\n",
       "                                     verbose=0, warm_start=False),\n",
       "    n_features_to_select=2, step=1, verbose=1)"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fit the model to the training data\n",
    "rfe.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!../gitbsh"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
