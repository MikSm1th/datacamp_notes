{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set_style('darkgrid')\n",
    "mpl.rcParams['figure.figsize'] = [18,10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "non_numeric = ['BMI_class', 'Height_class', 'Gender', 'Component', 'Branch']\n",
    "regression = ['BMI_class', 'Height_class', 'Gender', 'Component', 'Branch', 'BMI']\n",
    "\n",
    "def load_ansur(cols_to_drop, test_size, model_type='class'):\n",
    "    df_m = pd.read_csv('data/ANSUR_II_MALE.csv')\n",
    "    df_f = pd.read_csv('data/ANSUR_II_FEMALE.csv')\n",
    "    ansur_df = pd.concat([df_m, df_f], axis=0)\n",
    "    \n",
    "    if model_type == 'class': \n",
    "        X = ansur_df.drop(cols_to_drop, axis=1)\n",
    "        y = ansur_df['Gender']\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=test_size)\n",
    "    elif model_type == 'reg':\n",
    "        X = ansur_df.drop(cols_to_drop, axis=1)\n",
    "        y = ansur_df[\"BMI\"]\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=test_size)\n",
    "    else:\n",
    "        print('please specify model type')\n",
    "        \n",
    "    return X, y, X_train, X_test, y_train, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "def load_pima(cols_to_drop):\n",
    "    df = pd.read_csv('data/PimaIndians.csv')\n",
    "\n",
    "    X = df.drop(cols_to_drop, axis=1)\n",
    "    y = df['test']\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3)\n",
    "    return X, y, X_train, X_test, y_train, y_test\n",
    "\n",
    "X, y, X_train, X_test, y_train, y_test = load_pima('test')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature extraction \n",
    "### Feature generation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>storeID</th>\n",
       "      <th>product</th>\n",
       "      <th>quantity</th>\n",
       "      <th>revenue</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A</td>\n",
       "      <td>Apples</td>\n",
       "      <td>1811</td>\n",
       "      <td>9300.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A</td>\n",
       "      <td>Bananas</td>\n",
       "      <td>1003</td>\n",
       "      <td>3375.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>A</td>\n",
       "      <td>Oranges</td>\n",
       "      <td>1604</td>\n",
       "      <td>8528.5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  storeID  product  quantity  revenue\n",
       "0       A   Apples      1811   9300.6\n",
       "1       A  Bananas      1003   3375.2\n",
       "2       A  Oranges      1604   8528.5"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sales_df = pd.read_csv('data/grocery_sales.csv')\n",
    "sales_df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  storeID  product     price\n",
      "0       A   Apples  5.135616\n",
      "1       A  Bananas  3.365105\n",
      "2       A  Oranges  5.317020\n",
      "3       B   Apples  5.143417\n",
      "4       B  Bananas  3.898517\n"
     ]
    }
   ],
   "source": [
    "# Calculate the price from the quantity sold and revenue\n",
    "sales_df['price'] = sales_df.revenue/sales_df.quantity\n",
    "\n",
    "# Drop the quantity and revenue features\n",
    "reduced_df = sales_df.drop(['quantity', 'revenue'], axis=1)\n",
    "\n",
    "print(reduced_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y, X_train, X_test, y_train, y_test = load_ansur(non_numeric, 0.3)\n",
    "y = y.map({\"Male\":1, \"Female\":0})\n",
    "df = X\n",
    "df['gender'] = y\n",
    "#df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Principle component analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-3.51674371e+00  1.59374878e+00 -8.08230517e-01 ... -4.36363115e-02\n",
      "   5.28128161e-02  1.52702201e-02]\n",
      " [ 8.30842190e-01  2.06436542e+00 -1.25006217e+00 ...  5.15906913e-02\n",
      "  -2.67285268e-02  1.98695000e-02]\n",
      " [-5.71342970e+00 -1.17930607e+00 -1.09541044e+00 ... -7.09899034e-02\n",
      "  -3.26406702e-03 -6.79468060e-02]\n",
      " ...\n",
      " [ 3.92273351e+00 -2.42152121e+00  2.42973003e+00 ...  1.08307643e-01\n",
      "  -1.30813641e-01  1.82733652e-02]\n",
      " [ 1.08510311e+01 -1.41402737e+00  1.45659251e+00 ...  1.51538913e-01\n",
      "   2.51262482e-02  6.86466609e-02]\n",
      " [ 7.75056165e+00  1.05226348e+00  3.32876020e-01 ...  5.31085541e-02\n",
      "   2.37015728e-02  1.09083700e-02]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaler = StandardScaler()\n",
    "std_df = scaler.fit_transform(df)\n",
    "\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "pca = PCA()\n",
    "print(pca.fit_transform(std_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['abdominalextensiondepthsitting', 'acromialheight',\n",
       "       'acromionradialelength', 'anklecircumference', 'axillaheight',\n",
       "       'balloffootcircumference', 'balloffootlength', 'biacromialbreadth',\n",
       "       'bicepscircumferenceflexed', 'bicristalbreadth', 'bideltoidbreadth',\n",
       "       'bimalleolarbreadth', 'bitragionchinarc', 'bitragionsubmandibulararc',\n",
       "       'bizygomaticbreadth', 'buttockcircumference', 'buttockdepth',\n",
       "       'buttockheight', 'buttockkneelength', 'buttockpopliteallength',\n",
       "       'calfcircumference', 'cervicaleheight', 'chestbreadth',\n",
       "       'chestcircumference', 'chestdepth', 'chestheight', 'crotchheight',\n",
       "       'crotchlengthomphalion', 'crotchlengthposterioromphalion', 'earbreadth',\n",
       "       'earlength', 'earprotrusion', 'elbowrestheight', 'eyeheightsitting',\n",
       "       'footbreadthhorizontal', 'footlength', 'forearmcenterofgriplength',\n",
       "       'forearmcircumferenceflexed', 'forearmforearmbreadth',\n",
       "       'forearmhandlength', 'functionalleglength', 'handbreadth',\n",
       "       'handcircumference', 'handlength', 'headbreadth', 'headcircumference',\n",
       "       'headlength', 'heelanklecircumference', 'heelbreadth', 'hipbreadth',\n",
       "       'hipbreadthsitting', 'iliocristaleheight', 'interpupillarybreadth',\n",
       "       'interscyei', 'interscyeii', 'kneeheightmidpatella',\n",
       "       'kneeheightsitting', 'lateralfemoralepicondyleheight',\n",
       "       'lateralmalleolusheight', 'lowerthighcircumference',\n",
       "       'mentonsellionlength', 'neckcircumference', 'neckcircumferencebase',\n",
       "       'overheadfingertipreachsitting', 'palmlength', 'poplitealheight',\n",
       "       'radialestylionlength', 'shouldercircumference', 'shoulderelbowlength',\n",
       "       'shoulderlength', 'sittingheight', 'sleevelengthspinewrist',\n",
       "       'sleeveoutseam', 'span', 'suprasternaleheight', 'tenthribheight',\n",
       "       'thighcircumference', 'thighclearance', 'thumbtipreach', 'tibialheight',\n",
       "       'tragiontopofhead', 'trochanterionheight',\n",
       "       'verticaltrunkcircumferenceusa', 'waistbacklength', 'waistbreadth',\n",
       "       'waistcircumference', 'waistdepth', 'waistfrontlengthsitting',\n",
       "       'waistheightomphalion', 'wristcircumference', 'wristheight',\n",
       "       'weight_kg', 'stature_m', 'BMI', 'gender'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "ansur_df = X[['stature_m', 'buttockheight', 'waistcircumference', 'shouldercircumference']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.pairplot(ansur_df)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Create the scaler and standardize the data\n",
    "scaler = StandardScaler()\n",
    "ansur_std = scaler.fit_transform(ansur_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "\n",
    "pca = PCA()\n",
    "pc = pca.fit_transform(ansur_std)\n",
    "\n",
    "# This changes the numpy array output back to a dataframe\n",
    "pc_df = pd.DataFrame(pc, columns=['PC 1', 'PC 2', 'PC 3', 'PC 4'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a pairplot of the principal component dataframe\n",
    "sns.pairplot(pc_df)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice how, in contrast to the input features, none of the principal components are correlated to one another."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ansur_df = X[['stature_m', 'buttockheight', 'waistdepth', 'span', 'waistcircumference', 'shouldercircumference', \n",
    "              'footlength', 'handlength', 'functionalleglength', 'chestheight', 'chestcircumference',\n",
    "              'cervicaleheight', 'sittingheight']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scale the data\n",
    "scaler = StandardScaler()\n",
    "ansur_std = scaler.fit_transform(ansur_df)\n",
    "\n",
    "# Apply PCA\n",
    "pca = PCA()\n",
    "pca.fit(ansur_std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inspect the explained variance ratio per component\n",
    "print(pca.explained_variance_ratio_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "pipe = Pipeline([\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('reducer', PCA())\n",
    "])\n",
    "pc = pipe.fit_transform(ansur_df)\n",
    "\n",
    "print(pc[:,:2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y, X_train, X_test, y_train, y_test = load_ansur('span', 0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ansur_categories = pd.DataFrame()\n",
    "ansur_categories['PC 1'] = pc[:,0]\n",
    "ansur_categories['PC 2'] = pc[:,1]\n",
    "ansur_categories['Height_class'] = X['Height_class'].values\n",
    "ansur_categories['BMI_class'] = X['BMI_class'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.scatterplot(data=ansur_categories,\n",
    "               x='PC 1', y='PC 2',\n",
    "               hue='Height_class',\n",
    "               alpha= 0.4)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.scatterplot(data=ansur_categories,\n",
    "               x='PC 1', y='PC 2',\n",
    "               hue='BMI_class',\n",
    "               alpha= 0.4)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y, X_train, X_test, y_train, y_test = load_ansur(non_numeric, 0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "pipe = Pipeline([\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('reducer', PCA(n_components=3)),\n",
    "    ('classifier', RandomForestClassifier())\n",
    "])\n",
    "pipe.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(pipe.steps[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe.steps[1][1].explained_variance_ratio_.cumsum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(pipe.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "numerics = ['int16', 'int32', 'int64', 'float16', 'float32', 'float64']\n",
    "df = pd.read_csv('data/pokemon.csv', index_col=0)\n",
    "poke_df = df.select_dtypes(include=numerics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "poke_df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build the pipeline\n",
    "pipe = Pipeline([('scaler', StandardScaler()),\n",
    "        \t\t ('reducer', PCA(n_components=2))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe.fit(poke_df)\n",
    "vectors = pipe.steps[1][1].components_.round(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print feature effects\n",
    "print('PC 1 effects = ' + str(dict(zip(poke_df.columns, vectors[0]))))\n",
    "print('PC 2 effects = ' + str(dict(zip(poke_df.columns, vectors[1]))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "poke_cat_df = df.select_dtypes(exclude=[np.number])\n",
    "poke_cat_df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pc = pipe.fit_transform(poke_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add the 2 components to poke_cat_df\n",
    "poke_cat_df['PC 1'] = pc[:, 0]\n",
    "poke_cat_df['PC 2'] = pc[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.scatterplot(data=poke_cat_df, \n",
    "                x='PC 1', y='PC 2', hue='Type 1')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.scatterplot(data=poke_cat_df, \n",
    "                x='PC 1', y='PC 2', hue='Legendary')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('data/pokemon.csv')\n",
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.select_dtypes(include=[np.number])\n",
    "y = df['Legendary']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build the pipeline\n",
    "pipe = Pipeline([\n",
    "        ('scaler', StandardScaler()),\n",
    "        ('reducer', PCA(n_components=2)),\n",
    "        ('classifier', RandomForestClassifier(random_state=0))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit the pipeline to the training data\n",
    "pipe.fit(X_train, y_train)\n",
    "\n",
    "# Prints the explained variance ratio\n",
    "print(pipe.steps[1][1].explained_variance_ratio_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Score the accuracy on the test set\n",
    "accuracy = pipe.score(X_test, y_test)\n",
    "\n",
    "# Prints the model accuracy\n",
    "print('{0:.1%} test set accuracy'.format(accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build the pipeline\n",
    "pipe = Pipeline([\n",
    "        ('scaler', StandardScaler()),\n",
    "        ('reducer', PCA(n_components=3)),\n",
    "        ('classifier', RandomForestClassifier(random_state=0))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit the pipeline to the training data\n",
    "pipe.fit(X_train, y_train)\n",
    "\n",
    "# Prints the explained variance ratio\n",
    "print(pipe.steps[1][1].explained_variance_ratio_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Score the accuracy on the test set\n",
    "accuracy = pipe.score(X_test, y_test)\n",
    "\n",
    "# Prints the model accuracy\n",
    "print('{0:.1%} test set accuracy'.format(accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!jupyter nbconvert --to html 4_Feature_extraction.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!../gitbsh > /dev/null 2>&1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
