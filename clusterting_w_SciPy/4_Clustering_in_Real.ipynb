{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set_style('darkgrid')\n",
    "mpl.rcParams['figure.figsize'] = [18,10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dominant colors in images\n",
    "- All images consist of pixels \n",
    "- Each pixel has three values :RGB\n",
    "- Perform k-means on standardized RGB values to find cluster centers\n",
    "- Uses: Identify features in satellite images\n",
    "\n",
    "### Tools to find dominant colors\n",
    "- Convert image to pixels: `matplotlib.image.imread`\n",
    "- Display colors of cluster centers: `matplotlib.pyplot.imshow`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(810, 1305, 3)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import matplotlib.image as img\n",
    "image = img.imread('data/sea.jpg')\n",
    "image.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "r = []\n",
    "g = []\n",
    "b = []\n",
    "\n",
    "for row in image:\n",
    "    for pixel in row: \n",
    "        # A pixel contains RGB values\n",
    "        temp_r, temp_g, temp_b = pixel\n",
    "        r.append(temp_r)\n",
    "        g.append(temp_g)\n",
    "        b.append(temp_b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.cluster.vq import whiten"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "pixels = pd.DataFrame({'red': r,\n",
    "                      'blue': b,\n",
    "                      'green': g,\n",
    "                      'scaled_red': whiten(r),\n",
    "                      'scaled_green': whiten(g),\n",
    "                      'scaled_blue': whiten(b)})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.cluster.vq import kmeans, vq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "distortions = []\n",
    "num_clusters = range(1, 11)\n",
    "\n",
    "# Create a list of distortions from the kmeans method\n",
    "for i in num_clusters: \n",
    "    cluster_centers, distortion = kmeans(pixels[['scaled_red', 'scaled_blue', 'scaled_green']], i)\n",
    "    distortions.append(distortion)\n",
    "    \n",
    "# Create a data frame with two list - number of clusters and distortions \n",
    "elbow_plot = pd.DataFrame({'num_clusters': num_clusters,\n",
    "                          'distortions': distortions})\n",
    "\n",
    "# Create a line plot of num_clusters and distortions\n",
    "sns.lineplot(x='num_clusters', y='distortions', data = elbow_plot)\n",
    "plt.xticks(num_clusters)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Find dominant colors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster_centers, _ = kmeans(pixels[['scaled_red', 'scaled_blue', 'scaled_green']], 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "colors = []\n",
    "\n",
    "# Find Standard Deviations \n",
    "r_std, g_std, b_std = pixels[['red', 'green', 'blue']].std()\n",
    "\n",
    "# Scale actual RGB values in range of 0-1\n",
    "for cluster_center in cluster_centers:\n",
    "    scaled_r, scaled_g, scaled_b = cluster_center\n",
    "    colors.append((\n",
    "        scaled_r * r_std/255,\n",
    "        scaled_g * g_std/255,\n",
    "        scaled_b * b_std/255\n",
    "    ))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Display dominant colors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Dimensions: 2 x 3 (N x 3 matrix)\n",
    "print(colors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Dimensions 1 x 2 x 3 (1 x N x 3 matrix)\n",
    "plt.imshow([colors])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r = []\n",
    "g = []\n",
    "b = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import image class of matplotlib\n",
    "import matplotlib.image as img\n",
    "\n",
    "# Read batman image and print dimensions\n",
    "batman_image = img.imread('data/batman.jpg')\n",
    "print(batman_image.shape)\n",
    "\n",
    "# Store RGB values of all pixels in lists r, g and b\n",
    "for pixel in batman_image:\n",
    "    for temp_r, temp_g, temp_b in pixel:\n",
    "        r.append(temp_r)\n",
    "        g.append(temp_g)\n",
    "        b.append(temp_b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batman_df = pd.DataFrame({'red': r,\n",
    "                         'green': g,\n",
    "                         'blue': b,\n",
    "                         'scaled_red': whiten(r),\n",
    "                         'scaled_green': whiten(g),\n",
    "                         'scaled_blue': whiten(b)})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "distortions = []\n",
    "num_clusters = range(1, 7)\n",
    "\n",
    "# Create a list of distortions from the kmeans function\n",
    "for i in num_clusters:\n",
    "    cluster_centers, distortion = kmeans(batman_df[['scaled_red', 'scaled_blue','scaled_green']], i)\n",
    "    distortions.append(distortion)\n",
    "\n",
    "# Create a data frame with two lists, num_clusters and distortions\n",
    "elbow_plot = pd.DataFrame({'num_clusters': num_clusters,\n",
    "                         'distortions': distortions})\n",
    "\n",
    "# Create a line plot of num_clusters and distortions\n",
    "sns.lineplot(x='num_clusters', y='distortions', data = elbow_plot)\n",
    "plt.xticks(num_clusters)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster_centers, _ = kmeans(batman_df[['scaled_red', 'scaled_green', 'scaled_blue']], 3)\n",
    "colors = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get standard deviations of each color\n",
    "r_std, g_std, b_std = batman_df[['red', 'green', 'blue']].std()\n",
    "\n",
    "for cluster_center in cluster_centers:\n",
    "    scaled_r, scaled_g, scaled_b = cluster_center\n",
    "    # Convert each standardized value to scaled value\n",
    "    colors.append((\n",
    "        scaled_r * r_std / 255,\n",
    "        scaled_g * g_std / 255,\n",
    "        scaled_b * b_std / 255\n",
    "    ))\n",
    "\n",
    "# Display colors of cluster centers\n",
    "plt.imshow([colors])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Document clustering\n",
    "1. Clean data before processing\n",
    "2. Determine the importance of the terms in a document (in TF-IDF matrix)\n",
    "3. Cluster the TF-IDF matrix\n",
    "4. Find top terms, documents in each cluster\n",
    "\n",
    "### Clean and tokenize data\n",
    "- Convert text to into smaller parts called tokens, clean data for processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import word_tokenize\n",
    "import re\n",
    "\n",
    "def remove_noise(text, stop_words = []):\n",
    "    tokens = word_tokenize(text)\n",
    "    cleaned_tokens = []\n",
    "    for token in tokens:\n",
    "        token = re.sub('[^A-Za-z0-9]+', '', token)\n",
    "        if len(token) > 1 and token.lower() not in stop_words:\n",
    "            #Get lowercase\n",
    "            cleaned_tokens.append(token.lower())\n",
    "    return cleaned_tokens\n",
    "\n",
    "data = remove_noise(\"It is lovely weather we are having.\\\n",
    "              I hope the weather continues.\",\n",
    "             stop_words = ['it', 'is', 'we', 'the'])\n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Document term matrix and sparse matrices\n",
    "- Document term matrix formed\n",
    "- Most elements in matrix are zero\n",
    "\n",
    "![matrix](data/matrix.png)\n",
    "\n",
    "- Sparse matrix is created\n",
    "\n",
    "![sparse_matrix](data/sparse_matrix.png)\n",
    "\n",
    "### TF-IDF(Term Frequency - Inverse Document Frequency)\n",
    "- A weighted measure: evaluate how important a word is to a document in a collection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_vectorizer = TfidfVectorizer(max_df=0.8, max_features=50,\n",
    "                                 min_df=0.2, tokenizer=remove_noise)\n",
    "\n",
    "tfidf_matrix = tfidf_vectorizer.fit_transform(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clustering with sparse matrix\n",
    "- `kmeans` in SciPy does not support sparse matrices\n",
    "- Use `.todense()` to convert a matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster_centers, distortion = kmeans(tfidf_matrix.todense(), 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Top terms per cluster\n",
    "- Cluster centers: lists with a size "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
